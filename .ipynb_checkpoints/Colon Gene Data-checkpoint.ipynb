{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "http://genomics-pubs.princeton.edu/oncology/affydata/index.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Imputation\" data-toc-modified-id=\"Data-Imputation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Imputation</a></span></li><li><span><a href=\"#Data-Pre-processing\" data-toc-modified-id=\"Data-Pre-processing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Pre-processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Misc.-Cleaning\" data-toc-modified-id=\"Misc.-Cleaning-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Misc. Cleaning</a></span></li><li><span><a href=\"#Data-Normalization/Standardization\" data-toc-modified-id=\"Data-Normalization/Standardization-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data Normalization/Standardization</a></span></li><li><span><a href=\"#SMOTE\" data-toc-modified-id=\"SMOTE-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>SMOTE</a></span></li><li><span><a href=\"#Data-Plotting\" data-toc-modified-id=\"Data-Plotting-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Data Plotting</a></span></li></ul></li><li><span><a href=\"#SVM-with-PCA\" data-toc-modified-id=\"SVM-with-PCA-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SVM with PCA</a></span></li><li><span><a href=\"#Random-Forest-with-PCA\" data-toc-modified-id=\"Random-Forest-with-PCA-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Random Forest with PCA</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "pandas version: 0.23.1\n",
      "matplotlib version: 2.2.2\n",
      "NumPy version: 1.14.5\n",
      "SciPy version: 1.1.0\n",
      "scikit-learn version: 0.19.1\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import sys\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp \n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import sklearn \n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "#misc\n",
    "import random\n",
    "import time\n",
    "\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Hsa.3004,)</th>\n",
       "      <th>(Hsa.13491,)</th>\n",
       "      <th>(Hsa.13491,)</th>\n",
       "      <th>(Hsa.37254,)</th>\n",
       "      <th>(Hsa.541,)</th>\n",
       "      <th>(Hsa.20836,)</th>\n",
       "      <th>(Hsa.1977,)</th>\n",
       "      <th>(Hsa.44472,)</th>\n",
       "      <th>(Hsa.3087,)</th>\n",
       "      <th>(Hsa.1447,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(Hsa.2618,)</th>\n",
       "      <th>(Hsa.27285,)</th>\n",
       "      <th>(Hsa.41260,)</th>\n",
       "      <th>(Hsa.14822,)</th>\n",
       "      <th>(Hsa.336,)</th>\n",
       "      <th>(Hsa.984,)</th>\n",
       "      <th>(Hsa.35124,)</th>\n",
       "      <th>(Hsa.3952,)</th>\n",
       "      <th>(Hsa.32734,)</th>\n",
       "      <th>(Hsa.9683,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8589.4163</td>\n",
       "      <td>5468.2409</td>\n",
       "      <td>4263.4075</td>\n",
       "      <td>4064.9357</td>\n",
       "      <td>1997.8929</td>\n",
       "      <td>5282.3250</td>\n",
       "      <td>2169.7200</td>\n",
       "      <td>2773.4212</td>\n",
       "      <td>7526.3862</td>\n",
       "      <td>4607.6762</td>\n",
       "      <td>...</td>\n",
       "      <td>99.110714</td>\n",
       "      <td>67.56125</td>\n",
       "      <td>259.91250</td>\n",
       "      <td>138.89875</td>\n",
       "      <td>88.23250</td>\n",
       "      <td>39.667857</td>\n",
       "      <td>67.82875</td>\n",
       "      <td>75.67750</td>\n",
       "      <td>83.52250</td>\n",
       "      <td>28.70125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9164.2537</td>\n",
       "      <td>6719.5295</td>\n",
       "      <td>4883.4487</td>\n",
       "      <td>3718.1589</td>\n",
       "      <td>2015.2214</td>\n",
       "      <td>5569.9071</td>\n",
       "      <td>3849.0588</td>\n",
       "      <td>2793.3875</td>\n",
       "      <td>7017.7338</td>\n",
       "      <td>4802.2524</td>\n",
       "      <td>...</td>\n",
       "      <td>126.789290</td>\n",
       "      <td>92.23875</td>\n",
       "      <td>96.27625</td>\n",
       "      <td>150.59000</td>\n",
       "      <td>82.23750</td>\n",
       "      <td>85.033333</td>\n",
       "      <td>152.19500</td>\n",
       "      <td>186.56750</td>\n",
       "      <td>44.47250</td>\n",
       "      <td>16.77375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3825.7050</td>\n",
       "      <td>6970.3614</td>\n",
       "      <td>5369.9688</td>\n",
       "      <td>4705.6500</td>\n",
       "      <td>1166.5536</td>\n",
       "      <td>1572.1679</td>\n",
       "      <td>1325.4025</td>\n",
       "      <td>1472.2587</td>\n",
       "      <td>3296.9512</td>\n",
       "      <td>2786.5821</td>\n",
       "      <td>...</td>\n",
       "      <td>151.877380</td>\n",
       "      <td>82.71500</td>\n",
       "      <td>31.10250</td>\n",
       "      <td>193.92000</td>\n",
       "      <td>76.97250</td>\n",
       "      <td>224.620240</td>\n",
       "      <td>31.22500</td>\n",
       "      <td>42.65625</td>\n",
       "      <td>16.09250</td>\n",
       "      <td>15.15625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6246.4487</td>\n",
       "      <td>7823.5341</td>\n",
       "      <td>5955.8350</td>\n",
       "      <td>3975.5643</td>\n",
       "      <td>2002.6131</td>\n",
       "      <td>2130.5429</td>\n",
       "      <td>1531.1425</td>\n",
       "      <td>1714.6312</td>\n",
       "      <td>3869.7850</td>\n",
       "      <td>4989.4071</td>\n",
       "      <td>...</td>\n",
       "      <td>152.595240</td>\n",
       "      <td>41.68375</td>\n",
       "      <td>5.92500</td>\n",
       "      <td>183.00625</td>\n",
       "      <td>74.52875</td>\n",
       "      <td>67.710714</td>\n",
       "      <td>48.33875</td>\n",
       "      <td>42.52000</td>\n",
       "      <td>49.98250</td>\n",
       "      <td>16.08500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3230.3287</td>\n",
       "      <td>3694.4500</td>\n",
       "      <td>3400.7400</td>\n",
       "      <td>3463.5857</td>\n",
       "      <td>2181.4202</td>\n",
       "      <td>2922.7821</td>\n",
       "      <td>2069.2463</td>\n",
       "      <td>2948.5750</td>\n",
       "      <td>3303.3712</td>\n",
       "      <td>3109.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>126.464290</td>\n",
       "      <td>76.60375</td>\n",
       "      <td>161.35000</td>\n",
       "      <td>61.70125</td>\n",
       "      <td>54.56375</td>\n",
       "      <td>223.359520</td>\n",
       "      <td>73.09875</td>\n",
       "      <td>57.59875</td>\n",
       "      <td>7.48875</td>\n",
       "      <td>31.81250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (Hsa.3004,)  (Hsa.13491,)  (Hsa.13491,)  (Hsa.37254,)  (Hsa.541,)  \\\n",
       "0    8589.4163     5468.2409     4263.4075     4064.9357   1997.8929   \n",
       "1    9164.2537     6719.5295     4883.4487     3718.1589   2015.2214   \n",
       "2    3825.7050     6970.3614     5369.9688     4705.6500   1166.5536   \n",
       "3    6246.4487     7823.5341     5955.8350     3975.5643   2002.6131   \n",
       "4    3230.3287     3694.4500     3400.7400     3463.5857   2181.4202   \n",
       "\n",
       "   (Hsa.20836,)  (Hsa.1977,)  (Hsa.44472,)  (Hsa.3087,)  (Hsa.1447,)  \\\n",
       "0     5282.3250    2169.7200     2773.4212    7526.3862    4607.6762   \n",
       "1     5569.9071    3849.0588     2793.3875    7017.7338    4802.2524   \n",
       "2     1572.1679    1325.4025     1472.2587    3296.9512    2786.5821   \n",
       "3     2130.5429    1531.1425     1714.6312    3869.7850    4989.4071   \n",
       "4     2922.7821    2069.2463     2948.5750    3303.3712    3109.4131   \n",
       "\n",
       "      ...       (Hsa.2618,)  (Hsa.27285,)  (Hsa.41260,)  (Hsa.14822,)  \\\n",
       "0     ...         99.110714      67.56125     259.91250     138.89875   \n",
       "1     ...        126.789290      92.23875      96.27625     150.59000   \n",
       "2     ...        151.877380      82.71500      31.10250     193.92000   \n",
       "3     ...        152.595240      41.68375       5.92500     183.00625   \n",
       "4     ...        126.464290      76.60375     161.35000      61.70125   \n",
       "\n",
       "   (Hsa.336,)  (Hsa.984,)  (Hsa.35124,)  (Hsa.3952,)  (Hsa.32734,)  \\\n",
       "0    88.23250   39.667857      67.82875     75.67750      83.52250   \n",
       "1    82.23750   85.033333     152.19500    186.56750      44.47250   \n",
       "2    76.97250  224.620240      31.22500     42.65625      16.09250   \n",
       "3    74.52875   67.710714      48.33875     42.52000      49.98250   \n",
       "4    54.56375  223.359520      73.09875     57.59875       7.48875   \n",
       "\n",
       "   (Hsa.9683,)  \n",
       "0     28.70125  \n",
       "1     16.77375  \n",
       "2     15.15625  \n",
       "3     16.08500  \n",
       "4     31.81250  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ColonX = pd.read_csv(\"ColonX.csv\")\n",
    "ColonX.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "ColonNames = pd.read_csv(\"ColonNames.csv\")\n",
    "ColonNames.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "ColonX.columns = ColonNames\n",
    "ColonX.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x\n",
       "0  1\n",
       "1  0\n",
       "2  1\n",
       "3  0\n",
       "4  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40 tumor, 22 non tumor\n",
    "ColonY = pd.read_csv(\"ColonY.csv\")\n",
    "ColonY.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "ColonY = ColonY - 1\n",
    "ColonY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 62\n",
      "Number of genes: 2000\n",
      "(62, 2000)\n",
      "Number of patients: 62\n",
      "(62, 1)\n"
     ]
    }
   ],
   "source": [
    "# ColonX dataset info\n",
    "print(\"Number of patients: \"+ str(ColonX.shape[0]))\n",
    "print(\"Number of genes: \"+str(ColonX.shape[1]))\n",
    "print(ColonX.shape)\n",
    "\n",
    "# ColonY dataset info\n",
    "print(\"Number of patients: \"+str(ColonY.shape[0]))\n",
    "print(ColonY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc. Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 genes with >50% missing values excluded.\n"
     ]
    }
   ],
   "source": [
    "original = len(ColonX)\n",
    "ColonX = ColonX.dropna(thresh=0.5*len(ColonX.index), axis=1)\n",
    "print(str(original-len(ColonX)) + \" genes with >50% missing values excluded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No missing values\n",
    "\n",
    "ColonX.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate genes/columns removed: 89\n"
     ]
    }
   ],
   "source": [
    "# Handle duplicate genes in ColonX (columns are duplicated), no duplicate patients\n",
    "\n",
    "colCount = ColonX.shape[1]\n",
    "ColonX = ColonX.loc[:,~ColonX.columns.duplicated()]\n",
    "print(\"Duplicate genes/columns removed: \" + str(colCount - ColonX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with 0 variance removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Handle genes with all the same values\n",
    "\n",
    "colCount = ColonX.shape[1]\n",
    "ColonX = ColonX.drop(ColonX.std()[(ColonX.std() == 0)].index, axis=1)\n",
    "print(\"Columns with 0 variance removed: \" + str(colCount - ColonX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for null/infinite values: \n",
      "False\n",
      "True\n",
      "--------------------\n",
      "Should be false: False\n",
      "Should be true: True\n"
     ]
    }
   ],
   "source": [
    "# Check for null/infite values\n",
    "\n",
    "print(\"Check for null/infinite values: \")\n",
    "\n",
    "print(np.any(np.isnan(ColonX)))\n",
    "print(np.all(np.isfinite(ColonX)))\n",
    "#print(np.any(X_train.isnull().sum() != 0))\n",
    "\n",
    "ColonX = ColonX.dropna(axis = 1)\n",
    "print(\"-\"*20)\n",
    "\n",
    "print(\"Should be false: \" + str(np.any(np.isnan(ColonX))))\n",
    "print(\"Should be true: \" + str(np.all(np.isfinite(ColonX))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization/Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# Log normalization\n",
    "\n",
    "logtransformer = FunctionTransformer(np.log1p)\n",
    "ColonX = pd.DataFrame(logtransformer.transform(ColonX), \n",
    "                           index = ColonX.index, columns = ColonX.columns)\n",
    "\n",
    "ColonX.isin([np.nan, np.inf, -np.inf]).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile normalization\n",
    "quantiletransformer = QuantileTransformer(random_state = 0)\n",
    "\n",
    "ColonX = pd.DataFrame(quantiletransformer.fit_transform(ColonX), \n",
    "                          index = ColonX.index, columns = ColonX.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "ColonX = pd.DataFrame((ColonX-ColonX.mean())/ColonX.std(),\n",
    "                           index = ColonX.index, columns = ColonX.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value Check\n",
    "ColonX.head()\n",
    "ColonX.isin([np.nan, np.inf, -np.inf]).sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio = \"all\", kind = \"svm\", \n",
    "                       k_neighbors = 5, m_neighbors = 10,\n",
    "                       random_state = 0)\n",
    "\n",
    "X_columns = X_train.columns\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = pd.DataFrame(X_train, columns = X_columns)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "print(y_train.value_counts()/y_train.shape[0])\n",
    "print(y_test.value_counts()/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([('Hsa.1133',), ('Hsa.746',), ('Hsa.35652',)], dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample 9 column names from gene expression matrix\n",
    "n_plots = 3\n",
    "\n",
    "dataSample = ColonX.sample(n_plots, axis = 1).columns\n",
    "print(dataSample)\n",
    "\n",
    "# Set up plot\n",
    "\n",
    "\n",
    "# Build plot\n",
    "for i in range(len(dataSample)):\n",
    "    plt.subplot(n_plots,1,i+1)\n",
    "    plt.hist(ColonX[dataSample[i]], bins = 100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "X = np.array(ColonX.copy(deep = False))\n",
    "y = np.array(ColonY.copy(deep = False))\n",
    "\n",
    "k_fold = RepeatedStratifiedKFold(3, n_repeats = 50, random_state = 100)\n",
    "\n",
    "\n",
    "svmList = [#LinearSVC(penalty = \"l1\",\n",
    "           #     random_state = 0, dual = False),\n",
    "           SVC(kernel = \"linear\", C = 0.001)\n",
    "           #SVC(kernel = \"linear\", C = 0.0001)\n",
    "           #SVC(kernel = \"rbf\", C = 0.001)\n",
    "           #SVC(kernel = \"rbf\", C = 0.001, gamma = 0.01)\n",
    "        ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecx/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "roc_aucs = []\n",
    "\n",
    "# perform 3-fold cross validation n times\n",
    "\n",
    "for svm in svmList:\n",
    "    k = 1\n",
    "    for k, (train, test) in enumerate(k_fold.split(X, y)):\n",
    "\n",
    "        pca = PCA(n_components = 200)\n",
    "        pca.fit(X[train])\n",
    "        # Careful not to change X explicitly\n",
    "        X_train_PCA = pca.transform(X[train].copy())\n",
    "        X_test_PCA = pca.transform(X[test].copy())\n",
    "\n",
    "        svm.fit(X_train_PCA, y[train])\n",
    "\n",
    "        y_pred = svm.predict(X_test_PCA)\n",
    "        accuracy = svm.score(X_test_PCA, y[test])\n",
    "        roc_auc = roc_auc_score(y[test], y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        roc_aucs.append(roc_auc)\n",
    "\n",
    "\n",
    "        '''\n",
    "        print(\"[fold {0}] PCA, accuracy: {1:.5f}, ROC_AUC: {2:.5f}\".\n",
    "              format(k, accuracy, roc_auc))\n",
    "\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        print(confusion_matrix(y[test], y_pred))\n",
    "        cm = confusion_matrix(y[test], y_pred)/y[test].shape[0]\n",
    "        print(cm)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        # KNN testing\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "        knn.fit(X_train_PCA, y[train])\n",
    "        y_pred = knn.predict(X_test_PCA)\n",
    "        accuracy = knn.score(X_test_PCA, y[test])\n",
    "        roc_auc = roc_auc_score(y[test], y_pred)\n",
    "        print(accuracy, roc_auc)\n",
    "        '''\n",
    "\n",
    "\n",
    "        ###print(\"-\"*50)\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8603939393939394\n",
      "0.8467490842490842\n"
     ]
    }
   ],
   "source": [
    "np.array(accuracies).shape\n",
    "print(np.array(accuracies).mean())\n",
    "print(np.array(roc_aucs).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [5, 8, 15, 25, 30, None],\n",
      " 'max_features': ['log2', 'sqrt', None],\n",
      " 'min_samples_leaf': [1, 2, 5, 10],\n",
      " 'min_samples_split': [2, 5, 10, 15, 100],\n",
      " 'n_estimators': [120, 300, 500, 800, 1200]}\n",
      "(62, 1911)\n",
      "1    40\n",
      "0    22\n",
      "Name: x, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "#------------------------------\n",
    "# Random Forest Parameters\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [120, 300, 500, 800, 1200]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2', 'sqrt', None]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 8, 15, 25, 30, None]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# RandomSearch Grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "print(ColonX.shape)\n",
    "print(ColonY[\"x\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "[CV] n_estimators=500, min_samples_split=5, min_samples_leaf=2, max_features=log2, max_depth=25, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecx/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=500, min_samples_split=5, min_samples_leaf=2, max_features=log2, max_depth=25, bootstrap=False \n",
      "[CV] n_estimators=500, min_samples_split=5, min_samples_leaf=2, max_features=log2, max_depth=25, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecx/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=500, min_samples_split=5, min_samples_leaf=1, max_features=None, max_depth=15, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alecx/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/alecx/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0f52738132c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fit rf_random model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrf_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mColonX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColonY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 30, cv = 3, verbose = 2, scoring = \"roc_auc\",\n",
    "                               random_state = 0, n_jobs = -1)\n",
    "\n",
    "# Fit rf_random model\n",
    "rf_random.fit(ColonX, ColonY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
